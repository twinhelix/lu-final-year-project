package eee;

import java.util.LinkedList;
import java.util.List;

import utils.ExpertsDictionary;
import agent.IExpert;
import environment.GameHistory;
import expert.AbstractExpert;
import expert.titfortat.TitForTatExpert;

/***
 * The Exploration-Exploitation Experts method (EEE)
 * 
 * @author HassassiN
 * 
 */
public class ExploreExploitExpert extends AbstractExpert {

	// Array of experts that the EEE algorithm can employ
	private Advisor[] advisors;

	// Values needed
	private double prob, currentTotalScore;
	private Phase phase;
	private int agentChoice, i, maxStages, currentStage;
	private String[] strategies;

	public ExploreExploitExpert(int playerNo, String[] strategies) {
		this(playerNo, strategies, 0.7);
	}

	public ExploreExploitExpert(int playerNo, String[] strategies, double prob) {
		super(playerNo);
		this.prob = prob;
		this.strategies = strategies;
		populateExpertArray(strategies);

		phase = Phase.IDLE;
		agentChoice = 0;
		i = 1;
		currentTotalScore = 0;
		maxStages = 10;
		currentStage = 0;
	}

	@Override
	public String getName() {
		return "Explore Exploit Expert";
	}

	/***
	 * need to override set player number as all player numbers need to be reset
	 */
	@Override
	public void setPlayerNumber(int playerNo) {
		this.playerNo = playerNo;
		populateExpertArray(strategies);
	}

	/***
	 * Populates advisers array and initializes values
	 * 
	 */
	private void populateExpertArray(String[] strategies) {
		ExpertsDictionary dict = new ExpertsDictionary(playerNo, prob);

		advisors = new Advisor[strategies.length];

		for (int i = 0; i < advisors.length; i++) {
			IExpert e = dict.getExpert(strategies[i]);
			if (e == null) {
				e = new TitForTatExpert(playerNo);
			}
			advisors[i] = new Advisor(e);
		}
	}

	/**
	 * ÑExploration. An exploration phase consists of picking a random expert e
	 * (i.e., from the uniform distribution over {1,...,r}), and following eÕs
	 * recommendations for a certain number of stages depending on the variant
	 * of the method.
	 * 
	 * ÑExploitation. An exploitation phase consists of picking an expert e with
	 * maximum Me, breaking ties at random, and following eÕs recommendations
	 * for a certain number of stages depending on the variant of the method.
	 */
	@Override
	public boolean move(GameHistory history) {

		if (advisors == null || advisors.length == 0) {
			return false;
		}
		currentStage++;

		if (history.getNumberOfMoves() == 0) {

			return explore(history);

		} else {
			// first always update previous round scores
			updateScores(history);

			if (currentStage > maxStages) {
				System.err.println("Phase: " + i);
				i++;
				updateLastPhase(maxStages);
				phase = Phase.IDLE;
				currentStage = 1;
			}
			if (phase == Phase.IDLE) {
				// A phase has just ended, update last phase and check
				// whether to explore or exploit

				double exploreProb = Math.random();

				if (exploreProb < prob) {
					// Perform Exploration phase --> update scores from last
					// phase first
					phase = Phase.EXPLORE;
					agentChoice = (int) (Math.random() * (advisors.length));
					System.err.println(advisors.length);
					System.err.println(agentChoice + ": "
							+ advisors[agentChoice].expert.getName());
					return explore(history);
				} else {
					phase = Phase.EXPLOIT;
					return exploit(history);
				}
				// Update last phase

			} else if (phase == Phase.EXPLORE) {
				return explore(history);
			} else {
				return exploit(history);
			}
		}
	}

	private boolean explore(GameHistory history) {
		// Use current experts advice
		return advisors[agentChoice].expert.move(history);
	}

	private boolean exploit(GameHistory history) {

		if (currentStage == 1) {
			findBestExpert();
		}
		// Use current experts advice
		return advisors[agentChoice].expert.move(history);
	}

	private void findBestExpert() {
		double bestScore = advisors[0].me;
		List<Integer> indices = new LinkedList<Integer>();
		indices.add(0);

		for (int i = 0; i < advisors.length; i++) {
			if (advisors[i].me == bestScore) {
				indices.add(i);
			} else if (advisors[i].me > bestScore) {
				bestScore = advisors[i].me;
				indices.clear();
				indices.add(i);
			}
		}
		agentChoice = (int) (Math.random() * indices.size());
	}

	private void updateScores(GameHistory history) {
		currentTotalScore += history.getPlayerLastScore(playerNo);
	}

	private void updateLastPhase(int stages) {
		// Find Average:
		double averageReward = currentTotalScore / stages;
		// Update Number of phases
		advisors[agentChoice].ne++;
		// Update Number of stages
		advisors[agentChoice].se += stages;
		// Update Average reward of phases followed
		advisors[agentChoice].me = advisors[agentChoice].me
				+ (((double) stages) / advisors[agentChoice].se)
				* (averageReward - advisors[agentChoice].me);
	}
}
