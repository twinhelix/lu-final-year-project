package eee;

import java.util.LinkedList;
import java.util.List;

import utils.ExpertsDictionary;
import agent.IExpert;
import environment.GameHistory;
import expert.AbstractExpert;
import expert.titfortat.TitForTatExpert;

/***
 * The Exploration-Exploitation Experts method (EEE)
 * 
 * @author HassassiN
 * 
 */
public class ExploreExploitExpert extends AbstractExpert {

	private final boolean DEBUG = true;

	// Array of experts that the EEE algorithm can employ
	private Advisor[] advisors;

	// Values needed
	private double prob, currentTotalScore;
	private Phase phase;
	private int agentChoice, i, maxStages, currentStage;
	private String[] strategies;

	public ExploreExploitExpert(int playerNo, String[] strategies) {
		this(playerNo, strategies, 0.3);
	}

	public ExploreExploitExpert(int playerNo, String[] strategies, double prob) {
		super(playerNo);
		this.prob = prob;
		this.strategies = strategies;
		initialize();
	}

	@Override
	public void initialize() {
		populateExpertArray(strategies);
		phase = Phase.IDLE;
		agentChoice = 0;
		i = 1;
		currentTotalScore = 0;
		maxStages = 10;
		currentStage = 0;
	}

	@Override
	public String getName() {
		return "Explore Exploit Expert";
	}

	/***
	 * need to override set player number as all player numbers need to be reset
	 */
	@Override
	public void setPlayerNumber(int playerNo) {
		this.playerNo = playerNo;
		populateExpertArray(strategies);
	}

	/***
	 * Populates advisers array and initializes values
	 * 
	 */
	private void populateExpertArray(String[] strategies) {
		ExpertsDictionary dict = new ExpertsDictionary(playerNo, 0.2);

		advisors = new Advisor[strategies.length];

		for (int i = 0; i < advisors.length; i++) {
			IExpert e = dict.getExpert(strategies[i]);
			if (e == null) {
				e = new TitForTatExpert(playerNo);
			}
			advisors[i] = new Advisor(e);
		}
	}

	/**
	 * ÑExploration. An exploration phase consists of picking a random expert e
	 * (i.e., from the uniform distribution over {1,...,r}), and following eÕs
	 * recommendations for a certain number of stages depending on the variant
	 * of the method.
	 * 
	 * ÑExploitation. An exploitation phase consists of picking an expert e with
	 * maximum Me, breaking ties at random, and following eÕs recommendations
	 * for a certain number of stages depending on the variant of the method.
	 */
	@Override
	public boolean move(GameHistory history) {

		if (advisors == null || advisors.length == 0) {
			return false;
		}

		currentStage++;

		if (history.getNumberOfMoves() == 0) {

			return explore(history);

		} else {
			// first always update previous round scores
			updateScores(history);

			if (currentStage > maxStages) {
				// End of a phase
				if (DEBUG)
					System.out.println("Phase: " + i);
				i++;
				updateLastPhase(maxStages);
				currentTotalScore = 0;
				phase = Phase.IDLE;
				currentStage = 1;
			}

			if (phase == Phase.IDLE) {
				// A phase has just ended, update last phase and check
				// whether to explore or exploit

				double exploreProb = Math.random();

				if (exploreProb < prob) {
					// Perform Exploration phase --> update scores from last
					// phase first
					phase = Phase.EXPLORE;
					agentChoice = (int) (Math.random() * (advisors.length));
					if (DEBUG)
						System.out.println("PICKING TO EXPLORE: "
								+ advisors[agentChoice].expert.getName());
					return explore(history);
				} else {
					phase = Phase.EXPLOIT;
					return exploit(history);
				}
				// Update last phase

			} else if (phase == Phase.EXPLORE) {
				return explore(history);
			} else if (phase == Phase.EXPLOIT) {
				return exploit(history);
			}
		}
		return false;
	}

	private boolean explore(GameHistory history) {
		// Use current experts advice
		return advisors[agentChoice].expert.move(history);
	}

	private boolean exploit(GameHistory history) {

		if (currentStage == 1) {
			findBestExpert();
			if (DEBUG) {
				showExpertList();
				System.out.println("PICKING TO EXPLOIT: "
						+ advisors[agentChoice].expert.getName());
			}
		}
		// Use current experts advice
		return advisors[agentChoice].expert.move(history);
	}

	private void showExpertList() {
		// TODO Auto-generated method stub
		for (int i = 0; i < advisors.length; i++) {
			System.out.println(advisors[i].expert.getName() + " "
					+ advisors[i].aveReward);
		}
		System.out.println();
	}

	private void findBestExpert() {
		double bestScore = advisors[0].aveReward;
		List<Integer> indices = new LinkedList<Integer>();
		indices.add(0);

		for (int i = 0; i < advisors.length; i++) {
			if (advisors[i].aveReward == bestScore) {
				indices.add(i);
			} else if (advisors[i].aveReward > bestScore) {
				bestScore = advisors[i].aveReward;
				indices.clear();
				indices.add(i);
			}
		}

		agentChoice = indices.get((int) (Math.random() * indices.size()));
	}

	private void updateScores(GameHistory history) {
		currentTotalScore += history.getPlayerLastScore(playerNo);
	}

	private void updateLastPhase(int stages) {
		// Find Average:
		double averageReward = currentTotalScore / stages;
		// Update Number of phases
		advisors[agentChoice].phase++;
		// Update Number of stages
		advisors[agentChoice].stage += stages;
		// Update Average reward of phases followed
		advisors[agentChoice].aveReward = advisors[agentChoice].aveReward
				+ (((double) stages) / advisors[agentChoice].stage)
				* (averageReward - advisors[agentChoice].aveReward);
	}
}
